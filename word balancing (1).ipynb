{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a compiler is a special program that processes statements written in a particular programming language and turns them into machine language there are two parts to compile: analysis and synthesis. symbol table is an important data structure created and maintained by the compiler in order to keep track of the semantics of variable basically have two phases of compilers, namely analysis phase and synthesis phase. the lr parser is a non recursive, shift reduce, bottom up parser. its use as a wide class of context-free grammar"
     ]
    }
   ],
   "source": [
    "for line in open('C:/Users/Keerthi/Downloads/TeleDesktop/output.txt'):       \n",
    "    # Use file iterators to read by lines \n",
    "    print(line.lower(), end='')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : 5\n",
      "compiler : 2\n",
      "is : 3\n",
      "special : 1\n",
      "program : 1\n",
      "that : 1\n",
      "processes : 1\n",
      "statements : 1\n",
      "written : 1\n",
      "in : 2\n",
      "particular : 1\n",
      "programming : 1\n",
      "language : 2\n",
      "and : 4\n",
      "turns : 1\n",
      "them : 1\n",
      "into : 1\n",
      "machine : 1\n",
      "there : 1\n",
      "are : 1\n",
      "two : 2\n",
      "parts : 1\n",
      "to : 2\n",
      "compile: : 1\n",
      "analysis : 2\n",
      "synthesis. : 1\n",
      "symbol : 1\n",
      "table : 1\n",
      "an : 1\n",
      "important : 1\n",
      "data : 1\n",
      "structure : 1\n",
      "created : 1\n",
      "maintained : 1\n",
      "by : 1\n",
      "the : 3\n",
      "order : 1\n",
      "keep : 1\n",
      "track : 1\n",
      "of : 4\n",
      "semantics : 1\n",
      "variable : 1\n",
      "basically : 1\n",
      "have : 1\n",
      "phases : 1\n",
      "compilers, : 1\n",
      "namely : 1\n",
      "phase : 1\n",
      "synthesis : 1\n",
      "phase. : 1\n",
      "lr : 1\n",
      "parser : 1\n",
      "non : 1\n",
      "recursive, : 1\n",
      "shift : 1\n",
      "reduce, : 1\n",
      "bottom : 1\n",
      "up : 1\n",
      "parser. : 1\n",
      "its : 1\n",
      "use : 1\n",
      "as : 1\n",
      "wide : 1\n",
      "class : 1\n",
      "context-free : 1\n",
      "grammar : 1\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode \n",
    "text = open(\"C:/Users/Keerthi/Downloads/TeleDesktop/output.txt\", 'rt', encoding=\"iso-8859-1\") \n",
    "  \n",
    "# Create an empty dictionary \n",
    "d = dict() \n",
    "  \n",
    "# Loop through each line of the file \n",
    "for line in text: \n",
    "    # Remove the leading spaces and newline character \n",
    "    line = line.strip() \n",
    "  \n",
    "    # Convert the characters in line to  \n",
    "    # lowercase to avoid case mismatch \n",
    "    line = line.lower() \n",
    "  \n",
    "    # Split the line into words \n",
    "    words = line.split(\" \") \n",
    "  \n",
    "    # Iterate over each word in line \n",
    "    for word in words: \n",
    "        # Check if the word is already in dictionary \n",
    "        if word in d: \n",
    "            # Increment count of word by 1 \n",
    "            d[word] = d[word] + 1\n",
    "        else: \n",
    "            # Add the word to dictionary with count 1 \n",
    "                d[word] = 1\n",
    "         \n",
    "  \n",
    "# Print the contents of dictionary    d[word] = 1\n",
    "for key in list(d.keys()): \n",
    "    print(key, \":\", d[key]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compiler', 'special', 'program', 'processes', 'statements', 'written', 'particular', 'programming', 'language', 'turns', 'machine', 'language', 'two', 'parts', 'compile', 'analysis', 'synthesis', 'symbol', 'table', 'important', 'data', 'structure', 'created', 'maintained', 'compiler', 'order', 'keep', 'track', 'semantics', 'variable', 'basically', 'two', 'phases', 'compilers', 'namely', 'analysis', 'phase', 'synthesis', 'phase', 'lr', 'parser', 'non', 'recursive', 'shift', 'reduce', 'bottom', 'parser', 'use', 'wide', 'class', 'contextfree', 'grammar']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'C:/Users/Keerthi/Downloads/TeleDesktop/output.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])\n",
    "#print (str(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words after stopword removal:  52\n"
     ]
    }
   ],
   "source": [
    "print ('Number of words after stopword removal: ',str(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
